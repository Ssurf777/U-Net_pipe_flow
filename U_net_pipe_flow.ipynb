{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXlOdIeh2rhkh0H+3slP/v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ssurf777/U-Net_pipe_flow/blob/main/U_net_pipe_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CFD datasets import"
      ],
      "metadata": {
        "id": "J_1Uo7z7nJbb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_XRV8Bwm0Sz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "url = 'https://github.com/Ssurf777/U-Net_pipe_flow/raw/main/data/cfd_data.npy'\n",
        "r = requests.get(url)\n",
        "\n",
        "with open('cfd_data.npy', 'wb') as f:\n",
        "  f.write(r.content)\n",
        "\n",
        "data = np.load('cfd_data.npy')\n",
        "data.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization datasets"
      ],
      "metadata": {
        "id": "Si0k8d-qnSA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Extract x, y, and z columns\n",
        "x = data[:, 0]\n",
        "y = data[:, 1]\n",
        "z = data[:, 2]\n",
        "\n",
        "# Create a 3D scatter plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(x, y, z, s=1)  # s controls the size of the points\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title('3D Point Cloud Visualization')\n",
        "\n",
        "# Set the view angle to look from the positive y-axis\n",
        "ax.view_init(elev=0, azim=90) # elev is elevation, azim is azimuthal angle\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GCyYvUkInRrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "# x, y, z, psta を想定通り取得している前提\n",
        "x = data[:, 0]\n",
        "y = data[:, 1]\n",
        "z = data[:, 2]\n",
        "psta = data[:, 6]\n",
        "\n",
        "# カラーマップ付きの3D散布図\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "sc = ax.scatter(x, y, z, c=psta, cmap='viridis', s=1)  # pstaを色として指定\n",
        "\n",
        "# カラーバー追加\n",
        "cbar = plt.colorbar(sc, ax=ax, shrink=0.5)\n",
        "cbar.set_label('Psta')\n",
        "\n",
        "# ラベルやビュー設定\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title('3D Pressure Distribution (Pressure)')\n",
        "ax.view_init(elev=0, azim=90)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZOKB6FPBoEw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "# x, y, z, psta を想定通り取得している前提\n",
        "x = data[:, 0]\n",
        "y = data[:, 1]\n",
        "z = data[:, 2]\n",
        "psta = data[:, 3]\n",
        "\n",
        "# カラーマップ付きの3D散布図\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "sc = ax.scatter(x, y, z, c=psta, cmap='viridis', s=1)  # pstaを色として指定\n",
        "\n",
        "# カラーバー追加\n",
        "cbar = plt.colorbar(sc, ax=ax, shrink=0.5)\n",
        "cbar.set_label('velocity of u')\n",
        "\n",
        "# ラベルやビュー設定\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title('3D Pressure Distribution (velo. of u)')\n",
        "ax.view_init(elev=0, azim=90)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bnoWtWelpeym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "# x, y, z, psta を想定通り取得している前提\n",
        "x = data[:, 0]\n",
        "y = data[:, 1]\n",
        "z = data[:, 2]\n",
        "psta = data[:, 4]\n",
        "\n",
        "# カラーマップ付きの3D散布図\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "sc = ax.scatter(x, y, z, c=psta, cmap='viridis', s=1)  # pstaを色として指定\n",
        "\n",
        "# カラーバー追加\n",
        "cbar = plt.colorbar(sc, ax=ax, shrink=0.5)\n",
        "cbar.set_label('velocity of v')\n",
        "\n",
        "# ラベルやビュー設定\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title('3D Pressure Distribution (velo. of v)')\n",
        "ax.view_init(elev=0, azim=90)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "H-_dBt5Op_0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "# x, y, z, psta を想定通り取得している前提\n",
        "x = data[:, 0]\n",
        "y = data[:, 1]\n",
        "z = data[:, 2]\n",
        "psta = data[:, 5]\n",
        "\n",
        "# カラーマップ付きの3D散布図\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "sc = ax.scatter(x, y, z, c=psta, cmap='viridis', s=1)  # pstaを色として指定\n",
        "\n",
        "# カラーバー追加\n",
        "cbar = plt.colorbar(sc, ax=ax, shrink=0.5)\n",
        "cbar.set_label('velocity of w')\n",
        "\n",
        "# ラベルやビュー設定\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title('3D Pressure Distribution (velo. of w)')\n",
        "ax.view_init(elev=0, azim=90)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dirSJX5KqQut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# U-Net define"
      ],
      "metadata": {
        "id": "POK-0sJ5quH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def mish(x):\n",
        "    return x * torch.tanh(F.softplus(x))\n",
        "\n",
        "def init_weights_kaiming(module):\n",
        "    if isinstance(module, nn.Conv1d):\n",
        "        nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')  # Mish用のHeもrelu指定で問題なし\n",
        "        if module.bias is not None:\n",
        "            nn.init.zeros_(module.bias)\n",
        "\n",
        "class PointNetEncoder(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, 64, 1)\n",
        "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = nn.Conv1d(128, 256, 1)\n",
        "        self.apply(init_weights_kaiming)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)        # [B, 3, N]\n",
        "        x1 = mish(self.conv1(x))     # [B, 64, N]\n",
        "        x2 = mish(self.conv2(x1))    # [B, 128, N]\n",
        "        x3 = mish(self.conv3(x2))    # [B, 256, N]\n",
        "        return x1, x2, x3\n",
        "\n",
        "class PointNetDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.upconv1 = nn.Conv1d(256 + 128, 128, 1)\n",
        "        self.upconv2 = nn.Conv1d(128 + 64, 64, 1)\n",
        "        self.out = nn.Conv1d(64, 4, 1)\n",
        "        self.apply(init_weights_kaiming)\n",
        "\n",
        "    def forward(self, x1, x2, x3):\n",
        "        up1 = mish(self.upconv1(torch.cat([x3, x2], dim=1)))  # [B, 128, N]\n",
        "        up2 = mish(self.upconv2(torch.cat([up1, x1], dim=1))) # [B, 64, N]\n",
        "        out = self.out(up2)                                   # [B, 4, N]\n",
        "        return out.transpose(1, 2)                            # [B, N, 4]\n",
        "\n",
        "class PointUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = PointNetEncoder()\n",
        "        self.decoder = PointNetDecoder()\n",
        "\n",
        "    def forward(self, x):  # x: [B, N, 3]\n",
        "        x1, x2, x3 = self.encoder(x)\n",
        "        out = self.decoder(x1, x2, x3)\n",
        "        return out  # [B, N, 4]\n"
      ],
      "metadata": {
        "id": "FSfY-68oqcVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataloader"
      ],
      "metadata": {
        "id": "35KsN7Ft2Fvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class CFDDataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        super().__init__()\n",
        "        data = np.load(data_path)  # shape: (N, 7)\n",
        "        self.inputs = data[:, 0:3].astype(np.float32)  # x, y, z\n",
        "        #self.targets = data[:, 3:7].astype(np.float32)  # u, v, w, p\n",
        "        self.targets = data[:, 6].astype(np.float32)  # p\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.targets[idx]\n"
      ],
      "metadata": {
        "id": "fZo5yI9WuiEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class CFDDataset2(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        super().__init__()\n",
        "        data = np.load(data_path).astype(np.float32)  # shape: (N, 7)\n",
        "        self.inputs = data[:, 0:3]    # x, y, z\n",
        "        self.raw_targets = data[:, 6] # p\n",
        "\n",
        "        # --- Min-Max Scaling ---\n",
        "        self.p_min = self.raw_targets.min()\n",
        "        self.p_max = self.raw_targets.max()\n",
        "        self.targets = (self.raw_targets - self.p_min) / (self.p_max - self.p_min)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.targets[idx]\n",
        "\n",
        "    def inverse_transform(self, norm_p):\n",
        "        \"\"\"正規化されたpを元のスケールに戻す\"\"\"\n",
        "        return norm_p * (self.p_max - self.p_min) + self.p_min\n"
      ],
      "metadata": {
        "id": "3_GvhbBbz_2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データ読み込み\n",
        "train_dataset = CFDDataset2('cfd_data.npy')\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=False, drop_last=True)\n"
      ],
      "metadata": {
        "id": "j8Mmtc7YumNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer"
      ],
      "metadata": {
        "id": "R4PZbIO72JMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = PointUNet().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Epoch loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch_inputs, batch_targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        # reshape [B, 3] → [B, N, 3] : ここでN=1として扱う（点ごとに）\n",
        "        batch_inputs = batch_inputs.unsqueeze(1).to(device)   # shape: [B, 1, 3]\n",
        "        batch_targets = batch_targets.unsqueeze(1).to(device) # shape: [B, 1, 4]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_inputs)  # shape: [B, 1, 4]\n",
        "        loss = criterion(outputs, batch_targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Loss: {epoch_loss/len(train_loader):.6f}\")\n"
      ],
      "metadata": {
        "id": "vLPe7XwVqtVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# モデルを評価モードに\n",
        "model.eval()\n",
        "\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_inputs, batch_targets in tqdm(train_loader, desc=\"Predicting\"):\n",
        "        # batch_inputs: [B, N, 3]\n",
        "        # batch_targets: [B, N] または [B, N, 1]\n",
        "        batch_inputs = batch_inputs.to(device)\n",
        "        batch_targets = batch_targets.to(device)\n",
        "\n",
        "        # モデル出力 [B, N, 4]\n",
        "        outputs = model(batch_inputs)\n",
        "\n",
        "        # pの予測値を抽出（出力の4番目）\n",
        "        p_pred = outputs[:, :, 3].cpu().numpy()  # shape: [B, N]\n",
        "        p_true = batch_targets.cpu().numpy()     # shape: [B, N]\n",
        "\n",
        "        all_predictions.append(p_pred)\n",
        "        all_targets.append(p_true)\n",
        "\n",
        "# shape: [total_samples]\n",
        "predicted_pressure_normalized = np.concatenate(all_predictions, axis=0).flatten()\n",
        "target_pressure_normalized = np.concatenate(all_targets, axis=0).flatten()\n",
        "\n",
        "# 元スケールに戻す\n",
        "predicted_pressure_original = train_dataset.inverse_transform(predicted_pressure_normalized)\n",
        "target_pressure_original = train_dataset.inverse_transform(target_pressure_normalized)\n",
        "\n",
        "# R²スコア\n",
        "r2 = r2_score(target_pressure_original, predicted_pressure_original)\n",
        "print(f\"\\nR² Score (Pressure): {r2:.4f}\")\n",
        "\n",
        "# 散布図の描画\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(target_pressure_original, predicted_pressure_original, alpha=0.5, s=1)\n",
        "plt.xlabel(\"Actual Pressure\")\n",
        "plt.ylabel(\"Predicted Pressure\")\n",
        "plt.title(\"Actual vs. Predicted Pressure\")\n",
        "plt.grid(True)\n",
        "\n",
        "# 完全一致の赤線\n",
        "min_val = min(target_pressure_original.min(), predicted_pressure_original.min())\n",
        "max_val = max(target_pressure_original.max(), predicted_pressure_original.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Perfect Prediction')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "g9yoB4Mkxyod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Individual scalre Training using U-Net"
      ],
      "metadata": {
        "id": "p0nS_L6B6EDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "\n",
        "# --------------------------------------------\n",
        "# Mish Activation\n",
        "# --------------------------------------------\n",
        "def mish(x):\n",
        "    return x * torch.tanh(F.softplus(x))\n",
        "\n",
        "# --------------------------------------------\n",
        "# Kaiming Initialization\n",
        "# --------------------------------------------\n",
        "def init_weights_kaiming(module):\n",
        "    if isinstance(module, nn.Conv1d):\n",
        "        nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
        "        if module.bias is not None:\n",
        "            nn.init.zeros_(module.bias)\n",
        "\n",
        "# --------------------------------------------\n",
        "# Simple PointNet-like U-Net Block for Scalar Output\n",
        "# --------------------------------------------\n",
        "class ScalarUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, 64, 1)\n",
        "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = nn.Conv1d(128, 256, 1)\n",
        "\n",
        "        self.up1 = nn.Conv1d(256 + 128, 128, 1)\n",
        "        self.up2 = nn.Conv1d(128 + 64, 64, 1)\n",
        "        self.out = nn.Conv1d(64, 1, 1)\n",
        "\n",
        "        self.apply(init_weights_kaiming)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)  # [B, 3, N]\n",
        "        x1 = mish(self.conv1(x))\n",
        "        x2 = mish(self.conv2(x1))\n",
        "        x3 = mish(self.conv3(x2))\n",
        "\n",
        "        up1 = mish(self.up1(torch.cat([x3, x2], dim=1)))\n",
        "        up2 = mish(self.up2(torch.cat([up1, x1], dim=1)))\n",
        "        out = self.out(up2)  # [B, 1, N]\n",
        "        return out.transpose(1, 2)  # [B, N, 1]\n",
        "\n",
        "# --------------------------------------------\n",
        "# Combined Model with 4 U-Nets and Physics Loss\n",
        "# --------------------------------------------\n",
        "class PhysicsInformedCFDModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net_u = ScalarUNet()\n",
        "        self.net_v = ScalarUNet()\n",
        "        self.net_w = ScalarUNet()\n",
        "        self.net_p = ScalarUNet()\n",
        "\n",
        "    def forward(self, coords):\n",
        "        # coords: [B, N, 3] with requires_grad=True\n",
        "        u = self.net_u(coords)  # [B, N, 1]\n",
        "        v = self.net_v(coords)\n",
        "        w = self.net_w(coords)\n",
        "        p = self.net_p(coords)\n",
        "        return u, v, w, p\n",
        "\n",
        "    def pde_loss(self, coords, u, v, w, p):\n",
        "        grads_u = grad(u, coords, grad_outputs=torch.ones_like(u), create_graph=True)[0]  # [B, N, 3]\n",
        "        grads_v = grad(v, coords, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
        "        grads_w = grad(w, coords, grad_outputs=torch.ones_like(w), create_graph=True)[0]\n",
        "\n",
        "        du_dx = grads_u[:, :, 0]\n",
        "        dv_dy = grads_v[:, :, 1]\n",
        "        dw_dz = grads_w[:, :, 2]\n",
        "\n",
        "        continuity = du_dx + dv_dy + dw_dz  # [B, N]\n",
        "        loss_cont = torch.mean(continuity ** 2)\n",
        "\n",
        "        return loss_cont\n"
      ],
      "metadata": {
        "id": "TgfORQMW6L7M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}